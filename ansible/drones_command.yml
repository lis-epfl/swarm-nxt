---
- name: Command
  hosts: drones
  remote_user: lis
  become: yes # runs everything with sudo

  # vars_prompt: 
  #   - name: command
  #     prompt: "What command do you want to run on all of the drones (WARNING: Runs as sudo!)?"
  #     private: false  
  # tasks:
    # - name: Command
    #   ansible.builtin.command: '{{ command }}'
    # - name: "Common Components"
    #   ansible.builtin.include_tasks: "tasks/install-gurobi13.yml"

  tasks:
    - name: Set max power mode with confirmation
      become: true
      ansible.builtin.shell: echo "yes" | nvpmodel -m 0
      register: nvpmodel_output
      # We use shell because command doesn't support pipes (|)
  #   - name: Install nvidia toolkit (System Package)
  #     ansible.builtin.apt:
  #       name: nvidia-jetpack
  #       state: present
  #       update_cache: yes

  #   - name: Jetson Stats
  #     ansible.builtin.pip:
  #       name:
  #         - jetson-stats

  #   - name: Install ONNX Runtime (C++ Dev Files)
  #     become: true
  #     block:
  #       - name: Install onnxruntime-gpu pip package (JetPack 6)
  #         pip:
  #           name: onnxruntime-gpu
  #           extra_args: "--index-url https://pypi.jetson-ai-lab.io/jp6/cu126 --upgrade"
  #           executable: pip3

  #       - name: Find onnxruntime location
  #         shell: pip3 show onnxruntime-gpu | grep Location | cut -d " " -f 2
  #         register: ort_pip_loc
  #         changed_when: false

  #       - name: Symlink ONNX Runtime libraries
  #         shell: |
  #           ln -sf {{ ort_pip_loc.stdout }}/onnxruntime/capi/libonnxruntime.so.* /usr/local/lib/
  #           ln -sf {{ ort_pip_loc.stdout }}/onnxruntime/capi/libonnxruntime_providers_*.so /usr/local/lib/

  #           ORT_SO=$(find {{ ort_pip_loc.stdout }}/onnxruntime/capi -name "libonnxruntime.so.*" | head -n 1)
  #           ln -sf $ORT_SO /usr/local/lib/libonnxruntime.so

  #           ldconfig

  #       - name: Download and Install ONNX Runtime Headers
  #         shell: |
  #           set -e
  #           ORT_TAG="v1.17.0"
  #           ORT_VERSION="1.17.0"

  #           if [ ! -f /usr/local/include/onnxruntime_cxx_api.h ]; then
  #             wget "https://github.com/microsoft/onnxruntime/archive/refs/tags/$ORT_TAG.tar.gz" -O /tmp/ort.tar.gz
  #             tar -xf /tmp/ort.tar.gz -C /tmp/

  #             cp -r "/tmp/onnxruntime-$ORT_VERSION/include/onnxruntime/core/session/"* /usr/local/include/
  #             cp -r "/tmp/onnxruntime-$ORT_VERSION/include/onnxruntime/core/providers/"* /usr/local/include/ 2>/dev/null || true

  #             rm -rf /tmp/ort.tar.gz "/tmp/onnxruntime-$ORT_VERSION"
  #           fi
  #         args:
  #           executable: /bin/bash

    # - name: Configure real-time priority limits for the current user 
    #   ansible.builtin.copy:
    #     dest: /etc/security/limits.d/99-realtime.conf
    #     content: |
    #       lis    -    rtprio   99
    #       lis    -    memlock  unlimited
    #     owner: root
    #     group: root
    #     mode: '0644'
    #   become: true
    # - name: Copy Gurobi license file
    #   ansible.builtin.copy:
    #     src: secrets/gurobi.lic
    #     dest: /opt/gurobi/gurobi.lic
    #     mode: '0644'
    #     owner: root
    #     group: root

    # - name: Send files
    #   ansible.builtin.template:
    #     src: "{{ item.src }}"
    #     dest: "{{ item.dest }}"
    #     mode: "644"
    #   loop:
        # - { src: "../ros_packages/safety_checker_ros2/config/safety_params.yaml", dest: "{{ drone_ros_path }}/src/safety_checker_ros2/config/safety_params.yaml"}
        # - { src: "../ros_packages/drone_state_manager_ros2/config/drone_state_manager_params.yaml", dest: "{{ drone_ros_path }}/src/drone_state_manager_ros2/config/drone_state_manager_params.yaml"}
        # - { src: "/home/toumieh/ros2_ws/src/multi_agent_pkgs/multi_agent_planner/config/agent_omninxt_config.yaml", dest: "{{ drone_ros_path }}/src/multi_agent_pkgs/multi_agent_planner/config/agent_omninxt_config.yaml"}
        # - { src: "/home/toumieh/ros2_ws/src/mpc_controller_pkgs/mpc_controller_ros2/config/mpc_omninxt_params.yaml", dest: "{{ drone_ros_path }}/src/mpc_controller_pkgs/mpc_controller_ros2/config/mpc_omninxt_params.yaml"}
    # - name: Camera prereqs (DepthAI v3.2.1)
    #   block:
    #     - name: Ensure Movidius udev rule exists
    #       ansible.builtin.copy:
    #         content: 'SUBSYSTEM=="usb", ATTRS{idVendor}=="03e7", MODE="0666"'
    #         dest: /etc/udev/rules.d/80-movidius.rules
    #         mode: '0644'
    #       register: udev_rule_result

    #     - name: Reload udev rules if changed
    #       ansible.builtin.shell: udevadm control --reload-rules && udevadm trigger
    #       when: udev_rule_result.changed

    #     - name: Check if DepthAI library headers exist (Simple check)
    #       ansible.builtin.stat:
    #         path: /usr/local/include/depthai/depthai.hpp
    #       register: depthai_installed

    #     - name: Download and install depthai-core v3.2.1 (Source)
    #       when: not depthai_installed.stat.exists
    #       block:
    #         - name: Download depthai-core
    #           ansible.builtin.get_url:
    #             url: https://github.com/luxonis/depthai-core/releases/download/v3.2.1/depthai-core-v3.2.1.tar.gz
    #             dest: /tmp/depthai-core-v3.2.1.tar.gz

    #         - name: Extract depthai-core
    #           ansible.builtin.unarchive:
    #             src: /tmp/depthai-core-v3.2.1.tar.gz
    #             dest: /tmp
    #             remote_src: true

    #         - name: Build depthai-core (Shared Libs)
    #           ansible.builtin.shell: |
    #             cmake -S . -B build -DBUILD_SHARED_LIBS=ON
    #             cmake --build build --parallel $(nproc)
    #           args:
    #             chdir: /tmp/depthai-core-v3.2.1

    #         - name: Install depthai-core
    #           become: true
    #           ansible.builtin.shell: cmake --install build
    #           args:
    #             chdir: /tmp/depthai-core-v3.2.1

    #     - name: Run ldconfig
    #       ansible.builtin.command: ldconfig



